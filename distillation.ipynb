{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n"
      ],
      "metadata": {
        "id": "9_tkCrGvYenX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "HIpzdOJIZTlM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "T7nu6x-PYey3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучать буду на датасете CIFAR-10 "
      ],
      "metadata": {
        "id": "XROBuKaNvCAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLN2gGaLYe1M",
        "outputId": "146f8765-2894-4ccc-b58e-de883dacc705"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])"
      ],
      "metadata": {
        "id": "ak-ONOFnYe3I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_epochs = 5\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "temperature = 5.0\n",
        "distillation_weight = 0.5"
      ],
      "metadata": {
        "id": "B0p2Ha1WYoma"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве учителя используется ResNet-18"
      ],
      "metadata": {
        "id": "sleaZ1idvKOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = resnet18(pretrained=False, num_classes=10).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(teacher_model.parameters(), lr=learning_rate)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in tqdm(enumerate(train_loader)):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = teacher_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Teacher Model - Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "teacher_model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = teacher_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\"Teacher Model Accuracy on Test Images: {:.2f}%\".format(correct / total * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2Mp3_NyYog1",
        "outputId": "c32d0659-9ec2-4bc4-8ffa-2da664ded41c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [02:40,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [1/5], Step [100/391], Loss: 1.5572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [05:20,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [1/5], Step [200/391], Loss: 1.5448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "300it [07:59,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [1/5], Step [300/391], Loss: 1.4886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "391it [10:25,  1.60s/it]\n",
            "100it [02:38,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [2/5], Step [100/391], Loss: 1.1459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [05:21,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [2/5], Step [200/391], Loss: 1.2174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "300it [08:04,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [2/5], Step [300/391], Loss: 1.1607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "391it [10:31,  1.61s/it]\n",
            "100it [02:40,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [3/5], Step [100/391], Loss: 0.9459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [05:21,  1.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [3/5], Step [200/391], Loss: 1.0380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "300it [08:00,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [3/5], Step [300/391], Loss: 0.9802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "391it [10:24,  1.60s/it]\n",
            "100it [02:40,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [4/5], Step [100/391], Loss: 0.8841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [05:20,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [4/5], Step [200/391], Loss: 1.0261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "300it [07:59,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [4/5], Step [300/391], Loss: 1.0062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "391it [10:23,  1.59s/it]\n",
            "100it [02:37,  1.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [5/5], Step [100/391], Loss: 0.9504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [05:16,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [5/5], Step [200/391], Loss: 1.0517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "300it [07:55,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model - Epoch [5/5], Step [300/391], Loss: 0.7258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "391it [10:18,  1.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model Accuracy on Test Images: 71.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение меньшей модели (ученика)"
      ],
      "metadata": {
        "id": "L0kNJpL2vYx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class StudentModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(StudentModel, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Linear(32 * 8 * 8, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "student_model = StudentModel(num_classes=10).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(student_model.parameters(), lr=learning_rate)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    student_model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = student_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Student Model - Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}\")\n",
        "            \n",
        "student_model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = student_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\"Student Model Accuracy on Test Images: {:.2f}%\".format(correct / total * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY60E0yHYoau",
        "outputId": "0a4b8f98-bb5f-4fd3-aa01-d2bb39bbf694"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Model - Epoch [1/5], Step [100/391], Loss: 1.7929\n",
            "Student Model - Epoch [1/5], Step [200/391], Loss: 1.4300\n",
            "Student Model - Epoch [1/5], Step [300/391], Loss: 1.3890\n",
            "Student Model - Epoch [2/5], Step [100/391], Loss: 1.3421\n",
            "Student Model - Epoch [2/5], Step [200/391], Loss: 1.3992\n",
            "Student Model - Epoch [2/5], Step [300/391], Loss: 1.3474\n",
            "Student Model - Epoch [3/5], Step [100/391], Loss: 1.2704\n",
            "Student Model - Epoch [3/5], Step [200/391], Loss: 1.3158\n",
            "Student Model - Epoch [3/5], Step [300/391], Loss: 1.3159\n",
            "Student Model - Epoch [4/5], Step [100/391], Loss: 1.1564\n",
            "Student Model - Epoch [4/5], Step [200/391], Loss: 1.3136\n",
            "Student Model - Epoch [4/5], Step [300/391], Loss: 1.1402\n",
            "Student Model - Epoch [5/5], Step [100/391], Loss: 1.1487\n",
            "Student Model - Epoch [5/5], Step [200/391], Loss: 1.1138\n",
            "Student Model - Epoch [5/5], Step [300/391], Loss: 1.2185\n",
            "Student Model Accuracy on Test Images: 63.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дистилляция:"
      ],
      "metadata": {
        "id": "Hw9V63dGwm54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    student_model.train()\n",
        "    for i, (images, labels) in tqdm(enumerate(train_loader)):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            teacher_outputs = teacher_model(images)\n",
        "\n",
        "        student_outputs = student_model(images)\n",
        "\n",
        "        soft_targets = nn.functional.softmax(teacher_outputs / temperature, dim=1)\n",
        "\n",
        "        loss = criterion(student_outputs, labels) + distillation_weight * criterion(student_outputs, soft_targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuZcffb-Ye5l",
        "outputId": "c16ba243-994a-4ede-b297-05564f2c022a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "391it [02:54,  2.25it/s]\n",
            "391it [02:53,  2.26it/s]\n",
            "391it [02:53,  2.26it/s]\n",
            "391it [02:51,  2.28it/s]\n",
            "391it [02:52,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Model Accuracy after Distillation on Test Images: 68.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Итого:**\n",
        "\n",
        "Точность учителя: 71.48%\n",
        "\n",
        "Точность ученика: 63.14%\n",
        "\n",
        "Точность ученика после дистилляции: 68.23%"
      ],
      "metadata": {
        "id": "HovKCQ0SvuVh"
      }
    }
  ]
}